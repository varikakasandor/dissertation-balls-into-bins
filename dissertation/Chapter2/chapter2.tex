\chapter{Preparation}\label{preparation}

\ifpdf
    \graphicspath{{Chapter2/Figs/Raster/}{Chapter2/Figs/PDF/}{Chapter2/Figs/}}
\else
    \graphicspath{{Chapter2/Figs/Vector/}{Chapter2/Figs/}}
\fi



\section{Balls into Bins}


The simplest Balls into Bins models have been introduced as a probability theory problem under several different names in the 20th century (see e.g. \cite{kolchin1978coined}). A few years later its applicability to real world problems, such as load balancing, has been highlighted, and further research led to the analyses of even more realistic and efficient models. Apart from practical applications, the results derived for Balls into Bins models turned out to be useful in the analysis of several other (randomised) algorithms (see e.g. \cite{edmonds2006cakecutting}). It is still an emerging field gaining much attention, and in particular, the main model I will study has been first analysed in 2019 \cite{dwivedi2019firstthinning}.


\subsection{Definitions and Assumptions}



The real-world load balancing problem is very complex, and the exact characteristics differ between cases. For example, the servers might (or might not) be different (e.g. they serve different types of requests, or they just have different speed), the arrival rate of the jobs might be unknown (or maybe a model is possible), servers might crash, etc. Building a theoretical model that is completely general and can still be analysed effectively seems infeasible. Hence, most of the Balls into Bins models capture one or a few characteristics of load balancing, and therefore they are very diverse. There are however some common assumptions that all of models that I study make. Next I present a sufficiently general definition of the Balls into Bins abstraction, and state its assumptions. 


In the Balls into Bins problems, there are $n$ bins, and there are $m$ balls arriving sequentially. Whenever a ball arrives, it is placed in one of the bins according to a randomised protocol. \NOTE{A}{Use some LaTex definition/lemma/etc. framework, idk how.}


The (randomised) protocol is assessed according to some objective function, which is - unless I explicitly state otherwise in later chapters - the maximum load of the bins at the end of the process, and the smaller it is the better it is.\\


Assumptions:
\NOTE{A}{Explain better why I do actually make some assumptions, and not use the most general model possible.}


\begin{itemize}
    \item
    Balls never leave the bins. This corresponds to the real-world assumption that jobs are never completed. Having this simplifying assumption, it doesn't realistically model the actual server load of most real-world systems (where jobs usually end), but it can provide a good local approximation \NOTE{A}{explain} to that, and perfectly model the overall work completed by a server in a time period. There are nevertheless some Balls into Bins settings that also have deletion of the balls (see e.g. \cite{azar1999twochoice}, but I will not consider those in this dissertation.
    \item
    $m$ is known in advance. It is much easier to find good protocols when $m$ is known, e.g. as shown in \cite{feldheim2021longtermthinning}. In practice, even if $m$ is unknown, it might be estimated based on samples from previous runs (e.g. days).
    \item
    The balls and the bins are homogeneous. This assumes that there is just a single type of job, and all the servers are of the same quality. The more general case of heterogeneous balls and bins has also been analysed, see e.g. \cite{berenbrink2008weighted}.
\end{itemize}






\NOTE{A}{Maybe I shouldn't even try introducing it from the point of view of real world applications, and just simply say that researchers found many exciting and fun protocols to analyse?}

\NOTE{D}{The best thing would be to mention the assumptions that you think are unrealistic and propose how to address them.}






\subsection{Settings}

In this section I will define the randomised protocols that I will study in later chapters. Note that in the literature when they discuss a protocol, such as \textsc{One-Choice}, they often use the term (\textsc{One-Choice}) ``setting'', referring to the protocol being studied, and I will also use this terminology.


The general pattern in the protocols below is that they are more robust and are easier to implement than deterministic protocols (as discussed in \ref{introduction}), and some of them still provide sufficient guarantees on the objective function (maximum load). The theoretical analysis of the protocols according to the objective function is deferred until Chapter \ref{evaluation}.


\paragraph{\textsc{One-Choice}}

This is the simplest randomised algorithm. The arriving ball is allocated uniformly at random into one of the bins.

\paragraph{\textsc{Two-Choice}}

In this setting, two bins are chosen uniformly at random (possibly the same two bins \NOTE{A}{Double check this}), and the ball is placed in the lesser loaded of the two bins. In case of a tie, the ball is allocated uniformly at random into one of the two bins (note that in a version of \textsc{Two-Choice} that partitions the bins into $2$ groups and chooses one bin from each group, uniform tie-breaking is interestingly no longer optimal \cite{vocking2003tiebreaking}). In a real-world application of \textsc{Two-Choice}, choosing two bins uniformly at random and comparing their loads is a little bit more complicated. It can be achieved by choosing two servers uniformly at random (assuming that all the clients are aware of all the servers), sending a query request to the servers (independently to the two) about their load, then the servers interrupt their currently running processes and send back their load values to the client.

A generalisation of \textsc{Two-Choice} is \textsc{K-Choice}, where not $2$, but $k$ bins are compared - I do not discuss it any further, since it has been shown to provide only minor improvement over \textsc{Two-Choice} \cite{azar1999twochoice}.


\paragraph{\textsc{Two-Thinning}}


This is the main setting I will focus on. Here I present the main interpretation of this protocol, but in section \ref{alternative} I present another way to look at this setting. An important difference between this protocol, and \textsc{K-Choice} is that this protocol additionally requires a decision function, a free parameter of the protocol. When a ball arrives, a (primary) bin is chosen uniformly at random, and the according to the decision function, the primary bin is accepted, and the ball is placed into that bin, or it is rejected, and the ball is placed into a (secondary) bin chosen again uniformly at random. The motivation for this interpretation of \textsc{Two-Thinning} is that unlike for \textsc{Two-Thinning} where always $2$ servers are interrupted by a query, here if the primary load is accepted by the decision function, than only $1$ server is interrupted. A subtlety is that the secondary and primary bins can in fact be the same, while in a real-world application, the client would probably avoid the primary bin if it has been rejected.


\paragraph{\textsc{K-Thinning}}


\textsc{K-Thinning} is a generalisation of \textsc{Two-Thinning}, just like \textsc{K-Choice} for \textsc{Two-Choice}. Whenever a ball arrives, bin samples are taken uniformly at random until one of them is accepted by the decision function, and that is the bin where the ball is placed. Unlike for the \textsc{K-Choice} generalisation, this generalisation does provide a major improvement \cite{feldheim2020dthinning}.


\paragraph{\textsc{Graphical Two-Choice}}

This setting is similar to \textsc{Two-Choice} (which samples two bins uniformly at random), but not all pairs are equally likely. In particular, some pairs have the same probability, while others have a $0$ probability. Hence, treating each bin as a node of a graph, and pairs with nonzero probability as edges, the protocol becomes sampling an edge uniformly at random, and allocating the ball into the bin at one of the endpoints of the edge, \textbf{according to a decision function}. Note that remarkably, the greedy decision function, that allocates the ball into the lesser loaded of the two bins is not optimal, and hence this setting is also a parametric one, where a good decision function (``free parameter'') is required. A simple counterexample for why greedy is not optimal will be presented in Chapter \ref{evaluation}. It is often assumed that the graph is regular (i.e. all nodes have the same degree), otherwise the usual objective function (minimising final maximum load) is (even) less reasonable - take the star graph as an example of a highly unbalanced graph. The real-world motivation for this setting stems from the geographical locality of the servers. One possible interpretation is the client chooses an area uniformly at random, and a higher level server responsible for that area queries $2$ server there locally. In this case the edges correspond to nearby servers, different underlying graphs are also possible \cite{peres2015oneplusbeta}. In Section \ref{alternative} I discuss an alternative formulation of this setting with arguably stronger real-world motivation.

Analogously, \textsc{Graphical Two-Thinning} is a reasonable protocol, but I chose to focus on \textsc{Graphical Two-Choice}, since there is more literature available on that, and hence a more thorough comparative evaluation is possible.\\


As stated briefly in Chapter \ref{introduction}, the project is about optimising free parameters of various Balls into Bins settings. Now with the definitions in hand, we can see that it amounts to finding good decision functions for \textsc{Two-Thinning}, \textsc{K-Thinning} and \textsc{Graphical Two-Choice}. While most of the available decision functions are manually defined (e.g. choose the lesser loaded, or accept if greater than $x$), I will use algorithms to find good decision functions! Hence, I would like to make an important distinction between \textbf{protocol} and \textbf{algorithm}: an algorithm is used to optimise free parameters of a protocol, which can then be used in the balls into bins framework with the parameters generated by the algorithm. In particular, I will use RL and Dynamic Programming as algorithms, to find good decision functions for the parametric protocols discussed above. I will use this terminology from now on. On this note, I will use the terms \textbf{decision function} and the more general term \textbf{free parameters} interchangeably, always choosing based on the context. \NOTE{A}{Move elsewhere?}


\subsection{Notes on Related Work and Background Reading}

\NOTE{A}{Give more concrete examples?!}

From June 2021 to September 2021 I was reading several papers about the theory of Balls into Bins as preparation for the project. Now I present my main findings: 


\begin{itemize}
    \item 
    I wanted to understand why there are so many different settings, see how they are interconnected, and explore the main directions of current research. These allowed me to choose in a principled way which settings to focus on. In particular, \textsc{Two-Thinning}, the main setting of my study, has been analysed as a resource efficient protocol in-between \textsc{One-Choice} and \textsc{Two-Choice}. We can see a similar phenomenon the so-called \textsc{($1+\beta$)-process} \cite{peres2015oneplusbeta}.
    \item
    I found that most of the papers in this area approach the topic from a theoretical viewpoint, and there is a big gap between these results and the practical applications. Even though my approach is also a theoretical one, I found it important to gain practical motivation, and therefore I actively searched for papers bridging this gap, see e.g. \cite{wang2017twochoicerouting}.
    \item
    Even though this is not a proof-based project, I still wanted to gain an insight into how lower and upper bounds can be derived theoretically on the maximum load (or any other objective function) of various protocols. Therefore I followed along several proofs, e.g. that \textsc{Two-Choice} achieves a maximum load of $\frac{\ln(\ln(n))}{\ln(2)} + O(1)$ after $n$ balls \cite{azar1999twochoice}. These proofs didn't just provide insights into why or why not different protocols work well, but the proofs also provide intuition for improving protocols, or what is even more important for my project, creating good decision functions (i.e. finding good free parameters). For example, the so-called ``l-threshold strategy'' decision function for \textsc{Two-Thinning} is based on the observation that rejected balls form a \textsc{One-Choice} process, for which tight bounds are available \cite{feldheim2021thinning}.
    \item
    Perhaps surprisingly, the more general case where $m\neq n$ (usually $m>n$) is much more challenging than the $m=n$ case (i.e. where the number of balls equal the number of bins) \cite{berenbrink2006heavilyloaded}. This also manifests the gap between theory and practice - in real world applications the $m=n$ assumption can only hold in cases where the number of jobs is somehow controlled. As we will see in Chapter \ref{implementation}, my approaches will not be limited by this constraint.
    \item
    Almost exclusively all of the proofs are asymptotic - they only hold for very large $n$, mostly due to approximations, such as Stirling's formula \cite{feldheim2021thinning}. This is very restrictive for real-world applications, as discussed in Chapter \ref{introduction}. Similarly, (and sometimes also as a consequence of the above), the bounds hold only up to a constant/logarithmic factor, i.e. they are fixed only up to the $\Theta$ notation. In particular, there exist decision functions that have been shown to be optimal for \textsc{Two-Thinning}, such as the ``l-threshold strategy'' for $m=n$, but this is also not necessarily optimal for practically realistic values of $n$ and $m$! \NOTE{A}{Better phrasing. An interesting idea that I will get back to in Chapter \ref{evaluation} is trying to find out or bound the constant factors hidden behind the $\Theta$ notation, which would be very useful for comparisons.}
\end{itemize}


Combining many of the above points, I can say to the best of my knowledge that my work is novel in several aspects. The decision values I find using algorithms such as RL, are optimised for a specific value of $n$ and $m$, and hence have the capacity to outperform the asymptotically optimal, manually defined decision functions! In particular, using Dynamic Programming, I could find the ultimate best decision functions for moderate values of $n$ and $m$, exploiting that the state space is finite (i.e. there are just finitely many load configurations). Another important point is that the Balls into Bins framework is a stochastic process, therefore the final maximum load of a protocol is a distribution, and a choice has to be made on what property of the distribution to optimise (e.g. minimise the probability of very high values, or minimise the expected value, etc.). Unless where I explicitly state otherwise, my goal is to optimise the \textbf{expected} final maximum load of the resulting (after setting its free parameters) protocols. Interestingly, the theoretical results almost exclusively in the form ``the final maximum load is $\Theta(f(n))$ with high probability (w.h.p.)''. This is very interesting, and it highlights that the distribution is very concentrated around its mean as $n$ gets large! This is not true for the range of values that I am going to study, but it provides evidence for optimising (minimising) the expected value. \NOTE{A}{Explain the connection between the last 2 sentences better.}


\section{Reinforcement Learning}


\subsection{Finite Markov Decision Process (MDP)}


\subsection{Q-Learning}


\subsection{Sarsa-Learning}


\subsection{Deep Q-Learning}


\section{Real World VS Balls into Bins} \label{alternative}


Mention how full-knowledge can still be reasonable (Dimitris example)
For this we need the new interpretation, that servers communicate between themselves in the second round.
Also mention constant threshold, average threshold as using less information.
Mention the batched setting where the full-knowledge idea is even more applicable.


\section{Requirements Analysis}


\NOTE{A}{Add something about how the goal of the project has been shaped during the year.}

\NOTE{A}{Have to add a section about Starting Point? But it is already discuss in the Proforma and in the Proposal...}


\subsection{Software and Hardware}

For the project I chose to use Python as the programming language, for several reasons. The project has a large experimental part, trying out slight modifications quickly, writing a short script to test a hypothesis, etc., and Python is very convenient for such experimentation due to its compact syntax, and extensive library support (e.g. numpy, matplotlib). This library support comes with thorough documentation and a strong community, making it fairly easy to fix errors. I also used Python's object-oriented features for implementing the flexible evaluation environment. Perhaps the most important reason for choosing Python is its support for Deep Learning which I used in the Deep Q-Learning algorithm. For this, I chose Pytorch \cite{ketkar2021pytorch}, which is flexible, and increasingly popular deep learning library, supporting easy experimentation.


I used Pycharm as the IDE, for several reasons. It has a very easy-to-use and versatile debugger, which combined with the clarity of Pytorch tensors made finding out why some models don't work as desired more convenient. Also, it is very straightforward to run several experiments in parallel in Pycharm, which was also useful for experimentation. Finally, I already used Intellij in previous courses, making Pycharm and its Git and testing features already familiar.


I used my laptop for running all my code - its details are: Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz, 1992 Mhz, 4 Core(s), 8 Logical Processor(s), NVIDIA GeForce MX150 GPU. Gaining the expected speedup from GPUs for RL is not an easy problem, due to the difficulty of batching in the interactive MDP \cite{stooke2018gpudeepRL}. I will investigate further my approaches to exploit GPU in later chapters, here I just note that for the largest values I used ($n,m\leq 150$) training took a few (around $6$) hours and I didn't find it very instructive to increase $n$ and $m$ any further, so my laptop's resources were enough.


\subsection{Project Management}


I used Git for version control - it served as my primary backup, and also provides an easy-to-follow progression of my project via the commits. I additionally used Google Drive as a secondary backup, taking monthly copies. 

I used the work plan in my project proposal as the target schedule, and while my project has been on track throughout the whole year, it turned out to be beneficial to interleave evaluation and implementation work packages to gain better insights into what parts of the implementation to improve on. I also maintained a logbook, noting down all the todos and a summary of the work that has been completed. This logbook served as the baseline for my dissertation.

We had biweekly, and sometimes weekly meetings with my supervisors where we carefully assessed the progress of the project, and brainstormed several possible ideas for improvement and extension - some of which I didn't have time to implement and I mention in Chapter \ref{conclusion}.

I used LaTex for the dissertation, due to its support for custom formatting, references, and mathematical notation. I have written the dissertation in Overleaf, an online LaTex editor, due to its collaborative features, that made it easy to exchange comments with my supervisors. I also included the dissertation in the Git repository, regularly updating from Overleaf.

\NOTE{A}{Maybe risk saying some fancy Spiral methodology?}


\subsection{Risk Assessment}

Now I present the risk assessment of the project, which helped me prioritise components.

\begin{itemize}
    \item Background Reading
    
    Low risk, Medium difficulty
    
    I had no previous knowledge at all about RL, or Balls into Bins, so I had to do extensive background reading in both. Coming with a strong mathematical, and algorithms background I was confident that I will succeed in understanding both topics. Background reading was successful, I gained a deep understanding of the Balls into Bins literature, and explore the relevant parts of RL. The largest challenge was understanding the proofs in Balls into Bins papers, but I considered it as an extension, and I eventually succeeded and gained valuable insights.
    \item Implementing Deep Reinforcement Learning
    
    High risk, High difficulty
    
    The main risk involved in this main component was the uncertainty whether RL, being a novel approach, will actually work in optimising free parameters of Balls into Bins protocols. However, I want to emphasize that the goal of the project was to investigate how applicable it is, not showing that it is applicable. Eventually, RL was successfully applied, but some questions remain about its usefulness, as discussed in Chapter \ref{conclusion}.
    
    
    The main difficulty in the component was discovering which parts of the complex Deep Q-Learning need to be improved for better results, and exploring many possible optimisation ideas, as discussed in Section \ref{improvementideas}.
    
    \item Implementing classical algorithms
    
    Low risk, Low difficulty
    
    Having done much competitive programming, I was confident in my algorithmic knowledge, so I could efficiently develop and implement algorithms, such as Dynamic Programming.
    
    \item Evaluation
    
    Medium risk, Medium difficulty
    
    The hardest part about evaluation is finding the right metrics to use for comparing, and analysing algorithms and protocols. The medium risk stemmed from the possibility of not finding very instructive results, and the time it takes to run all the algorithms on various settings, getting acceptable confidence intervals.
    
    
\end{itemize}