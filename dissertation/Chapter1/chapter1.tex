\chapter{Introduction}\label{introduction}

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi


\section{Motivation}

Load balancing has been an important topic for many years, and it has gained even more attention recently e.g.\ cloud computing~\cite{mishra2020cloud}. In the usual setup, there are some servers, and whenever a job arrives, the goal is to allocate it to one of the servers such that no server is overloaded (which at high burden often requires also that no server is underloaded). At first glance, it might seem an easy problem to solve: always allocate the job greedily to the currently least loaded server. Or even simpler, in the case of homogeneous jobs: apply round-robin scheduling to the servers, using each of them in a cyclic way. 

The problem with these approaches is that they require a centralised load balancer. That central load balancer would be a single point of failure, reducing the robustness of the whole system, and decreasing performance due to its sequential nature\NOTE{D}{This is a very important point. For some applications, e.g., searching at Google, you cannot have all requests going through a single machine.}. An alternative is to use randomised load balancing. The idea is to allocate the jobs according to a random protocol -- the simplest being choosing a server uniformly at random -- that can be run independently on each client (requesting the job), without a central load balancer. The obvious question is how to shape this random protocol such that a good balance is achieved. A groundbreaking result in this topic was presented in~\cite{azar1999twochoice}. They showed that the \TwoChoice protocol, which always randomly queries the load of two independent servers, and allocates the job into the lesser loaded of the two, achieves a maximum load of $\frac{\ln(\ln(n))}{\ln(2)} + O(1)$ after $n$ jobs, with high probability (meaning that as $n$ goes to infinity, the probability converges to $1$). This result led to extensive further study of the topic (see e.g.~\cite{richa2001surveytwochoice}), and even large companies, such as Twitter started using this idea (often called ``The power of Two-Choices'')~\cite{anderson2019twitter}.


There are various versions of the load balancing problem (e.g.\ homogeneity of the jobs, random protocol used), and so for consistency reasons, the research community adapted the following standard abstraction: the servers are bins, and the jobs are balls. This is what I will use in the later chapters as well. This has the further advantage, that random protocols such as \TwoChoice have proved to be useful outside the field of load balancing too, e.g.\ hashing~\cite{azar1999twochoice}. See~\cite{udi2017ballsintobinslandscape} for a comprehensive survey. I will provide a more rigorous definition of the balls-into-bins abstraction in Chapter ~\ref{preparation}.


There are other random protocols suggested, that are more realistic, or more efficient than \TwoChoice in some circumstances.\NOTE{D}{Maybe start with stating which assumptions are unrealistic for load balancing using two-choice.} For example, we can see that if both of the bins queried by \TwoChoice have very low load, then, it was unnecessary to query both (e.g.\ communication overhead, slows down servers), and only one of them would be enough. \OneChoice, however, which simply allocates the ball uniformly at random (``takes 1 sample and accepts that'') has been shown to have exponentially worse maximum load (see e.g.\ the Randomised Algorithms course), so it is not sufficient. Something in the middle is \TwoThinning~\cite{feldheim2021thinning}, which samples one bin (``primary bin''), and either accepts that, or concludes that is has too high load, in which case the ball is allocated uniformly at random into one of the bins.\NOTE{D}{See email for the two interpretations of thinning.} This, on average, requires less than $2$ queries per ball, but it requires a decision strategy (or just ``strategy'') for whether to accept or reject a bin. This dissertation is about optimising such strategies in protocols like \TwoThinning, which I will call ``parametric protocols'' as they all require some extra input, usually a decision strategy. The goal is to optimise some objective function measuring how ``balanced'' the load distribution is, such as the maximum load of the bins after some number of balls have been allocated.



\section{My approach}

For finding good strategies, I will compare Reinforcement Learning (RL) methods with more classical approaches (e.g.\ dynamic programming) and other heuristics (e.g.\ mean thinning). RL is a natural choice, since we have to make optimal decisions (``choose ideal threshold for accept/reject'') in a dynamic, stochastic process. RL is based on collecting rewards, and a first idea could be getting a reward only after all the balls have been allocated (end of an execution), based on the final load distribution. There is more refinement needed, however, to make it work properly, which I will discuss in later chapters. RL has already been applied to load balancing in the literature, mostly related to networking~\cite{attiah2020RLcellular},~\cite{yeo2021controller}, but they use an abstraction slightly different from the balls-into-bins mode. The parametric balls-into-bins protocols I will study received much attention in the academic community only recently, though there have been earlier, mostly empirical studies as well (see. e.g.~\cite{derek1986twothinningfirstattempt}). At the moment, there are strategies (e.g.\ for \TwoThinning) that are proven to achieve optimal results up to a constant factor~\cite{feldheim2021thinning}, but only for very large values of balls and bins (the results are almost exclusively ``asymptotic''). Therefore, these results are of less help directly in real-world scenarios, where there are much less number of jobs and servers. There are $3$ reasons why most of these theoretical results are not applicable for small values: 1) the inequalities in the proofs don't work for small values~\cite{feldheim2021longtermthinning} so the theoretical guarantees might not hold, 2) the constant factor overhead in the result is significant and 3) suggested \textit{positive} integer parameter values used by the strategy would equal to $0$, e.g.\ $\floor{\ln(\ln(\ln(nunber\: of \: servers)))}$ which is usually $0$ even for large datacenters~\cite{uzaman2019datacentersize}.

\NOTE{D}{What about the two-thinning paper by Feldheim? or Mean-Thinning?}


Looking at the practical application of the \TwoThinning protocol, it is often much more natural and effective if the queried server itself decides whether to take the job, rather than sending back its current load value back to the client which makes the decision whether to accept of reject that server.  Overall, the process is 1) the client chooses a server uniformly at random, 2) the server either completes the job or passes it on to a server chosen uniformly at random.

The important question left is what information can the server use in deciding whether to accept a job or not. It needs some ``reference'' to assess its load relative to others, which requires some centralised information. There are several options, for example the servers could maintain the overall load of the system, or they could synchronise their individual loads from time-to-time (see e.g.~\cite{zhang2018datacenterloadbalancing} for efficient communication in data centers). I will focus on the latter, which crucially allows a server to make its decision based on the (possibly slightly outdated) loads of all the other servers. When a server decides to pass on the job to another one, the motivation for choosing the other server at random is that due to parallelism and the possibly outdated information, the seemingly least loaded server could quickly become the most overloaded if all the other servers pass the jobs to that one.


Having introduced the practical details, I will take a more theoretical approach in this project. Realising the lack of exact, non-asymptotical results even for simple settings, and to simplify the analysis, I will try to solve a simpler problem than the practical one presented above: the strategy is given the \textbf{exact load distribution} at the moment, and it is offered a specific (``primary'') bin, which it can either accept and place the ball there, or reject, in which case the ball is allocated to a ``secondary'' bin chosen uniformly at random. Another big simplification is that all the balls are allocated by a single instance of the strategy sequentially, i.e.\ the load distribution depends only on its own allocations. We will see that finding a good strategy even for this greatly simplified version proves to be very challenging for RL and other algorithms. When describing the candidate strategies I will highlight those that are more directly applicable in more realistic scenarios. \NOTE{A}{This is the single most important paragraph in the dissertation! Check if it is 100\% clear to the reader, both the motivation and the simplified problem.}


Overall, the intention of this dissertation is more to survey the applicability of RL and other approaches in different settings, than to provide directly practical protocols. Another aim of the project is to gain a deeper insight to how an optimal strategy looks like.
\NOTE{D}{I don't think you have put serious effort in highlighting the merits and results of your work in the above paragraph. Andor: This comment always makes me smile for some reason when I read it, so I don't delete it :) .}

\NOTE{D}{As discussed in the last meeting, even the non-RL setting you give it a load distribution and the NN needs to pick a threshold that will be used for the next $K$ steps is interesting, because it could work in a batched setting. Andor: what should I do with it?}


\section{Outline}

The outline of the dissertation is as follows.


In Chapter ~\ref{preparation}, I define the terms of the balls-into-bins terminology more precisely, and also make the underlying assumptions explicit. Then, I describe the balls-into-bins protocols that I will analyse in later chapters -- I do not discuss all of them at such length as I did in this chapter for \TwoThinning, but similar practical considerations apply\NOTE{A}{Is this sentence needed?}. Finally, I explain the basics of RL, with particular focus on Deep Q-Learning, which is the main algorithm that I used.


In Chapter ~\ref{implementation}, I explain the implementation details of RL and ``classical'' algorithms such as dynamic programming, for learning strategies for various parametric protocols. I also list several extensions of the simple RL algorithms that I implemented for better results, e.g.\ reward shaping. Finally, I explain the code structure with the extensible object-oriented style in focus.


In Chapter ~\ref{evaluation}, I compare the implemented approaches from different aspects, including how well they can balance the load, and their training complexity (if any). I also provide a thorough hyperparameter analysis for RL. As an extension, I analyse the behaviour of the different strategies. \NOTE{A}{Is it an extension?...}

In Chapter~\ref{conclusion} I conclude with some future work ideas for improving the RL approaches, gaining better insights to optimal strategies, and extending the study to different settings.