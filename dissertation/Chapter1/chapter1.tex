\chapter{Introduction}\label{introduction}

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi


\section{Motivation}

Load balancing has been an important topic for many years, and it has gained even more attention recently e.g. cloud computing \cite{mishra2020cloud}. In the usual setup, there are some servers, and whenever a job arrives, the goal is to allocate it to one of the servers such that no server is overloaded (which at high burden often also means that no server is underloaded). At first glance, it might seem an easy problem to solve: always allocate the job greedily to the currently least loaded server. Or even simpler, in the case of homogeneous jobs: apply round-robin scheduling to the servers, using each of them in a cyclic way. 

The problem with these approaches is that they require a centralised load balancer. That central load balancer would be a single of failure, reducing the robustness of the whole system, and potentially decreasing performance. An alternative is to use randomised load balancing! The idea is too allocate the jobs according to random protocol - the simplest being choosing a server randomly - that can be run independently on each client (requesting the job), without a central load balancer. The obvious question is how to shape this random protocol such that a good balance is achieved. The groundbreaking result in this topic was presented in \cite{azar1999twochoice}. They showed that the \textsc{Two-Choice} protocol, which always randomly queries the load of two independent servers, and allocates the job into the lesser loaded of the two, achieves a maximum load of $\frac{ln(ln(n))}{ln(2)} + O(1)$ after $n$ jobs, with high probability (meaning that as $n$ goes to infinity, the probability converges to $1$). This result led to extensive further study of the topic (see e.g. \cite{richa2001surveytwochoice}), and even large companies, such as Twitter started using this idea (often called ``The power of Two-Choices'') \cite{anderson2019twitter}.


There are various versions of the load balancing problem (e.g. homogeneity of the jobs, random protocol used), and so for consistency reasons, the research community adapted the following standard terminology from mathematics: the servers are bins, and the jobs are balls. This is what I will use in my dissertation as well from now on. This has the further advantage, that random protocols such as \textsc{Two-Choice} have proved to be useful outside the field of load balancing too, e.g. hashing \cite{azar1999twochoice}. I will provide a more rigorous definition of the balls into bins abstraction in Chapter \ref{preparation}.


There are other random protocols suggested, that are more realistic, or more efficient than \textsc{Two-Choice} in some circumstances. For example, we can see that if both of the bins queried by \textsc{Two-Choice} have very low load, then, it was unnecessary to do so (e.g. communication overhead, slows down servers), and only one of them would be enough. \textsc{One-Choice}, however, which simply allocates the ball randomly (``takes 1 sample and accepts that'') has been shown to have exponentially worse maximum load (see e.g. the Randomised Algorithms course), so it is not sufficient. Something in the middle is \textsc{Two-Thinning} \cite{feldheim2021thinning}, which samples one bin (``primary bin''), and either accepts that, or concludes that is has too high load, in which case the ball is allocated randomly into one of the bins. This, on average, requires less than $2$ queries per ball, but it is a parametric protocol: it depends on when it decides to accept a primary bin, and when it rejects it \NOTE{A}{How to be more clear about what parametric means, concisely?}. This dissertation is about optimising such free parameters in parametric protocols, like \textsc{Two-Thinning}.



\section{My approach}


For this optimisation procedure, I will mainly use Reinforcement Learning (RL). It is a natural choice, since we have to make optimal decisions (``choose ideal threshold for accept/reject'') in a dynamic, stochastic process. RL is based on rewards, and a first idea could be getting a reward only at the end of an execution, based on the final load distribution. There is more refinement needed, however, to make it work properly, which I will discuss in later chapters. RL has already been applied to load balancing in the literature, mostly related to networking \cite{attiah2020RLcellular}, \cite{yeo2021controller}. As mentioned earlier, load balancing is a very rich subject, and these aforementioned applications of RL to load balancing use a different abstraction, not the balls into bins model. Hence, these articles provide evidence that RL might work in our case as well, but they don't make this dissertation pointless. The parametric balls into bins models I will study received much attention in the academic community recently, and there are strategies for choosing the parameters (e.g. for \textsc{Two-Thinning}) that are proven to achieve optimal result up to a constant factor \cite{feldheim2021thinning}, but only for extremely large values of balls and bins (the results are almost exclusively ``asymptotic''). Therefore, these results are of less help directly in real-world scenarios, where there are much less number of jobs and servers. There are $3$ reasons why most of these theoretical results are not applicable for small values: 1) the inequalities in the proofs don't work for small values, 2) the constant overhead in the result is significant and 3) suggested positive integer parameter values would equal $0$, e.g. $\floor{ln(ln(ln(nunber\: of \: servers)))}$ which is usually $0$ even for large datacenters \cite{feldheim2021longtermthinning}.


Looking more closely at the \textsc{Two-Thinning} protocol, an important question is what information can we use in deciding whether to accept a primary bin or not. We need some ``reference'' to make a decision about the single queried load value. To keep the protocol decentralised, we would only be able to use the results of our queries for previous balls, nothing else. This information, however, doesn't mean anything without assumptions on the rate of other clients, who in the meanwhile also requested some jobs - maybe the previous query results are outdated. Therefore, we would either have to make assumptions about the job arrival rates, or compromise the decentralised nature of the protocol to some extent, since otherwise, without any information, the only possible threshold could be a global constant, which is not optimal. While the former is possible, I chose the latter for the following reason. Even if magically, the complete load distribution is known, it is still a challenging problem to make the decision whether to accept the primary bin - there is no obvious optimal strategy!


Based on this observation, while it would be possible to make the aforementioned compromise partial, by storing some limited shared state, I decided to take a theoretical, less practical approach to the project, by assuming that the complete load distribution is available when making the decision! This doesn't make much practical sense, since knowing the load distribution, there would be no need for querying, we could just allocate the ball into the least loaded bin. Having made this impractical assumption, there is no longer a need to distinguish different clients - we can reduce the problem to having a single client, and only the core challenge remains: choosing the currently optimal threshold for acceptance, based on the load distribution (which is known, since there are no external factors now). While this setting might seem illogical, there is merit in first testing the applicability of RL on this easier model, and I will also mention some ideas in Chapter \ref{implementation} for reducing the decentralizability compromise, and making it into a more realistic protocol. Overall, the intention of this dissertation is more to survey the applicability of RL in different settings, than to provide directly practical protocols.\NOTE{A}{This is the most important paragraph from the Introduction, it has to be crystal clear why I make these crazy assumptions! Or should I instead emphasize ``impractical'' less?}



\section{Outline}

The outline of the dissertation is as follows.


In Chapter \ref{preparation}, I define the terms of the balls into bins terminology more precisely, and also make the assumptions explicit (e.g. jobs don't get erased). Then, I describe the balls into bins models that I will analyse in later chapters, and highlight some non-RL based ideas that I will use in my comparisons later. Finally, I explain the basics of RL, with particular focus on Deep Q-Learning, which is the main algorithm that I used.


In Chapter \ref{implementation}, I explain the implementation details of RL and ``classical'' algorithms such as dynamic programming, for various different settings. I also list several extensions of the simple RL algorithms that I implemented for better results, e.g. reward shaping. Finally, I explain the code structure with the extensible object-oriented structure in focus.


In Chapter \ref{evaluation}, I compare algorithms from different aspect, including how well they can balance the load, and their training time. Then, I show a thorough hyperparameter optimisation, highlighting the relative parameter importance as well. Finally, I analyse the behaviour of the trained models, trying to explain the decisions they make.


In Chapter \ref{conclusion} I conclude the applicability of RL for balls into bins models and suggest future work, including different settings to analyse and possible ways to improve the RL algorithms.