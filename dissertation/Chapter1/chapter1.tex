\chapter{Introduction}\label{introduction}

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi


\section{Motivation}

Load balancing has been an important topic for many years, and it has gained even more attention recently e.g. cloud computing \cite{mishra2020cloud}.\NOTE{D}{Maybe also cite ``Hashing, Load Balancing and Multiple Choice'' by Wieder} In the usual setup, there are some servers, and whenever a job arrives, the goal is to allocate it to one of the servers such that no server is overloaded (which at high burden often also means that no server is\NOTE{T}{some servers are underloaded?} underloaded). At first glance, it might seem an easy problem to solve: always allocate the job greedily to the currently least loaded server. Or even simpler, in the case of homogeneous jobs: apply round-robin scheduling to the servers, using each of them in a cyclic way. 

The problem with these approaches is that they require a centralised load balancer. That central load balancer would be a single \NOTE{D}{point}of failure, reducing the robustness of the whole system, and potentially decreasing performance\NOTE{D}{This is a very important point. For some applications, e.g., searching at Google, you cannot have all requests going through a single machine.}. An alternative is to use randomised load balancing! The idea is to allocate the jobs according to random protocol -- the simplest being choosing a server \NOTE{D}{uniformly at random}randomly -- that can be run independently on each client (requesting the job), without a central load balancer. The obvious question is how to shape this random protocol such that a good balance is achieved. The\NOTE{T}{a} groundbreaking result in this topic was presented in \cite{azar1999twochoice}. They showed that the \textsc{Two-Choice}\NOTE{D}{You can define a command (see comment):
% \newcommand{\TwoChoice}{\textsc{Two-Choice}} 
to avoid re-typing each time. Same for other terms.} protocol, which always randomly queries the load of two independent servers, and allocates the job into the lesser loaded of the two, achieves a maximum load of $\frac{\ln(\ln(n))}{\ln(2)} + O(1)$ after $n$ jobs, with high probability (meaning that as $n$ goes to infinity, the probability converges to $1$). This result led to extensive further study of the topic (see e.g. \cite{richa2001surveytwochoice}), and even large companies, such as Twitter started using this idea (often called ``The power of Two-Choices'') \cite{anderson2019twitter}.


There are various versions of the load balancing problem (e.g. homogeneity of the jobs, random protocol used), and so for consistency reasons, the research community adapted the following standard terminology from mathematics\NOTE{T}{is this really from mathematics? I'd just write ``standard abstraction''}: the servers are bins, and the jobs are balls. This is what I will use in my dissertation as well from now on. This has the further advantage, that random protocols such as \textsc{Two-Choice} have proved to be useful outside the field of load balancing too, e.g. hashing \cite{azar1999twochoice}. I will provide a more rigorous definition of the balls into bins abstraction in Chapter \ref{preparation}.


There are other random protocols suggested, that are more realistic, or more efficient than \textsc{Two-Choice} in some circumstances.\NOTE{D}{Maybe start with stating which assumptions are unrealistic for load balancing using two-choice.} For example, we can see that if both of the bins queried by \textsc{Two-Choice} have very low load, then, it was unnecessary to do so (e.g. communication overhead, slows down servers), and only one of them would be enough. \textsc{One-Choice}, however, which simply allocates the ball randomly (``takes 1 sample and accepts that'') has been shown to have exponentially worse maximum load (see e.g. the Randomised Algorithms course), so it is not sufficient. Something in the middle is \textsc{Two-Thinning} \cite{feldheim2021thinning}, which samples one bin (``primary bin''), and either accepts that, or concludes that is has too high load, in which case the ball is allocated randomly into one of the bins.\NOTE{D}{See email for the two interpretations of thinning.} This, on average, requires less than $2$ queries per ball, but it is a parametric protocol\NOTE{D}{Maybe you could say that it requires a ``decision function'' for whether to accept or reject a bin. In the special case that this is a threshold function, it requires a single parameter.}\NOTE{T}{I agree with Dimitris. It is a bit unclear what parameter is. Also if we consider a time and load-dependent threshold function, it is much more then just ``one parameter''.}: it depends on when it decides to accept a primary bin, and when it rejects it \NOTE{A}{How to be more clear about what parametric means, concisely?}. This dissertation is about optimising such free parameters in parametric protocols, like \textsc{Two-Thinning}.



\section{My approach}


For this optimisation\NOTE{T}{not clear what you want to optimise. Also have you defined the gap yet?} procedure\NOTE{D}{You could start by saying that you will use RL to learn the decision function. }, I will mainly use Reinforcement Learning (RL). It is a natural choice, since we have to make optimal decisions (``choose ideal threshold for accept/reject'') in a dynamic, stochastic process. RL is based on rewards, and a first idea could be getting a reward only at the end of an execution, based on the final load distribution. There is more refinement needed, however, to make it work properly, which I will discuss in later chapters. RL has already been applied to load balancing in the literature, mostly related to networking \cite{attiah2020RLcellular}, \cite{yeo2021controller}. As mentioned earlier, load balancing is a very rich subject, and these aforementioned applications of RL to load balancing use a different abstraction, not the balls into bins model. Hence, these articles provide evidence that RL might work in our case as well, but they don't make this dissertation pointless\NOTE{D}{Why would they make it pointless if it is a different model?}. The parametric balls into bins models I will study received much attention in the academic community recently\NOTE{D}{The threshold version of two-thinning was being tested in the 80s (see https://www.cs.usask.ca/faculty/eager/loadsharing.pdf). But indeed only recently, versions of it have been analysed}, and there are strategies for choosing the parameters (e.g. for \textsc{Two-Thinning}) that are proven to achieve optimal result up to a constant factor \cite{feldheim2021thinning}, but only for extremely large values of balls and bins (the results are almost exclusively ``asymptotic''). Therefore, these results are of less help directly in real-world scenarios, where there are much less number of jobs and servers. There are $3$ reasons why most of these theoretical results are not applicable for small values: 1) the inequalities in the proofs don't work for small values\NOTE{D}{This is saying why the analysis is not working.}, 2) the constant overhead in the result is significant and 3) suggested positive integer parameter values would equal $0$, e.g. $\floor{\ln(\ln(\ln(nunber\: of \: servers)))}$ which is usually $0$ even for large datacenters \cite{feldheim2021longtermthinning}\NOTE{D}{You need to cite somewhere giving an upper bound on the number of datacenters.}.

\NOTE{D}{What about the two-thinning paper by Feldheim? or Mean-Thinning?}


Looking more closely at the \textsc{Two-Thinning} protocol, an important question is what information can we use in deciding whether to accept a primary bin or not. We need some ``reference'' to make a decision about the single queried load value. To keep the protocol decentralised, we would only be able to use the results of our queries for previous balls, nothing else \NOTE{T}{But if you start from an empty distribution, that means you know the entire load distribution?}. This information, however, doesn't mean anything without assumptions on the rate\NOTE{T}{I don't understand this. What does rate mean? How often a client submits a task?} of other clients, who in the meanwhile also requested some jobs - maybe the previous query results are outdated.\NOTE{D}{See note in the email.} Therefore, we would either have to make assumptions about the job arrival rates, or compromise the decentralised nature of the protocol to some extent, since otherwise, without any information, the only possible threshold could be a global constant, which is not optimal.\NOTE{D}{Knowing the total number of requests is a weaker synchronisation guarantee than knowing the exact load of each bin. For example, in mean-thinning if you add a bit of noise in the $m$ known by each bin, it does not affect much the maximum load.} While the former is possible, I chose the latter for the following reason. Even if magically\NOTE{D}{This phrasing is not fit for a dissertation}\NOTE{T}{absolutely agreed!}, the complete load distribution is known, it is still a challenging problem to make the decision whether to accept the primary bin - there is no obvious optimal strategy! \NOTE{T}{I would avoid exclamation marks (or use them only very rarely) in a formal document like dissertation.} \NOTE{D}{Also the motivation for the thinning paper is in discrepancy theory.}


Based on this observation, while it would be possible to make the aforementioned compromise partial, by storing some limited shared state, I decided to take a theoretical, less practical approach to the project, by assuming that the complete load distribution is available when making the decision! This doesn't make much practical sense,\NOTE{D}{This phrasing is not fit for a dissertation} since knowing the load distribution, there would be no need for querying, we could just allocate the ball into the least loaded bin. Having made this impractical assumption, there is no longer a need to distinguish different clients - we can reduce the problem to having a single client, and only the core challenge remains: choosing the currently optimal threshold for acceptance, based on the load distribution (which is known, since there are no external factors now). While this setting might seem illogical, there is merit in first testing the applicability of RL on this easier model, and I will also mention some ideas in Chapter \ref{implementation} for reducing the decentralizability compromise\NOTE{D}{Why mention these in the implementation if they are the more practical component?}, and making it into a more realistic protocol. Overall, the intention of this dissertation is more to survey the applicability of RL in different settings, than to provide directly practical protocols.\NOTE{A}{This is the most important paragraph from the Introduction, it has to be crystal clear why I make these crazy assumptions! Or should I instead emphasize ``impractical'' less?}
\NOTE{D}{I don't think you have put serious effort in highlighting the merits and results of your work in the above paragraph.}

\NOTE{D}{As discussed in the last meeting, even the non-RL setting you give it a load distribution and the NN needs to pick a threshold that will be used for the next $K$ steps is interesting, because it could work in a batched setting. }


\section{Outline}

The outline of the dissertation is as follows.


In Chapter \ref{preparation}, I define the terms of the balls into bins terminology more precisely, and also make the assumptions explicit (e.g. jobs don't get erased)\NOTE{T}{drop the (e.g.,...) here}. Then, I describe the balls into bins models that I will analyse in later chapters, and highlight some non-RL based ideas that I will use in my comparisons later. Finally, I explain the basics of RL, with particular focus on Deep Q-Learning, which is the main algorithm that I used.


In Chapter \ref{implementation}, I explain the implementation details of RL and ``classical'' algorithms such as dynamic programming, for various different settings. I also list several extensions of the simple RL algorithms that I implemented for better results, e.g. reward shaping. Finally, I explain the code structure with the extensible object-oriented structure in focus.


In Chapter \ref{evaluation}, I compare algorithms from different aspects, including how well they can balance the load, and their training time. Then, I show a thorough hyperparameter optimisation, highlighting the relative parameter importance as well. Finally, I analyse the behaviour of the trained models, trying to explain the decisions they make.


In Chapter \ref{conclusion} I conclude the applicability of RL for balls into bins models\NOTE{D}{RL was not the only investigation/result of the paper} and suggest future work, including different settings to analyse and possible ways to improve the RL algorithms.